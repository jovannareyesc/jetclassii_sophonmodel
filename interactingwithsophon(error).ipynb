{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLy6ztqXx0Si"
      },
      "source": [
        "# Interacting with JetClass-II and the Sophon model\n",
        "\n",
        "This is a self-contained notebook that\n",
        "\n",
        " - explores the JetClass-II dataset, and visualizes jet samples as point clouds\n",
        " - infers the Sophon model via ONNX in Python and inspects its output nodes  \n",
        "\n",
        "If you are looking for a C++ n-tuplizer to proceed Delphes ROOT files and integrate the Sophon model, refer to [this section](https://github.com/jet-universe/sophon/tree/main?tab=readme-ov-file#c-workflow-for-analyzing-delphes-files).\n",
        "\n",
        "This notebook is designed to [run on Google Colab](https://colab.research.google.com/github/jet-universe/sophon/blob/main/notebooks/Interacting_with_JetClassII_and_Sophon.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yny-wwkPx0Sm"
      },
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdsxRGM6x0Sn",
        "outputId": "3fe45cc2-8366-42e1-dfec-e4169186ea77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: weaver-core in /usr/local/lib/python3.11/dist-packages (0.4.17)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from weaver-core) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.2 in /usr/local/lib/python3.11/dist-packages (from weaver-core) (1.15.3)\n",
            "Requirement already satisfied: pandas>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from weaver-core) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from weaver-core) (1.6.1)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from weaver-core) (3.10.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from weaver-core) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from weaver-core) (6.0.2)\n",
            "Requirement already satisfied: awkward0>=0.15.5 in /usr/local/lib/python3.11/dist-packages (from weaver-core) (0.15.5)\n",
            "Requirement already satisfied: uproot<5.2.0,>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from weaver-core) (5.1.2)\n",
            "Requirement already satisfied: awkward>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from weaver-core) (2.8.5)\n",
            "Requirement already satisfied: vector>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from weaver-core) (1.6.2)\n",
            "Requirement already satisfied: lz4>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from weaver-core) (4.4.4)\n",
            "Requirement already satisfied: xxhash>=1.4.4 in /usr/local/lib/python3.11/dist-packages (from weaver-core) (3.5.0)\n",
            "Requirement already satisfied: tables>=3.6.1 in /usr/local/lib/python3.11/dist-packages (from weaver-core) (3.10.2)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from weaver-core) (2.18.0)\n",
            "Requirement already satisfied: awkward-cpp==47 in /usr/local/lib/python3.11/dist-packages (from awkward>=1.8.0->weaver-core) (47)\n",
            "Requirement already satisfied: fsspec>=2022.11.0 in /usr/local/lib/python3.11/dist-packages (from awkward>=1.8.0->weaver-core) (2025.3.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from awkward>=1.8.0->weaver-core) (8.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from awkward>=1.8.0->weaver-core) (24.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->weaver-core) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->weaver-core) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->weaver-core) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->weaver-core) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->weaver-core) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->weaver-core) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->weaver-core) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.3->weaver-core) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.3->weaver-core) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.1->weaver-core) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.1->weaver-core) (3.6.0)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.11/dist-packages (from tables>=3.6.1->weaver-core) (2.11.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from tables>=3.6.1->weaver-core) (9.0.0)\n",
            "Requirement already satisfied: blosc2>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from tables>=3.6.1->weaver-core) (3.5.1)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from tables>=3.6.1->weaver-core) (4.14.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2.0->weaver-core) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2.0->weaver-core) (1.73.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2.0->weaver-core) (3.8.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2.0->weaver-core) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2.0->weaver-core) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2.0->weaver-core) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2.0->weaver-core) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2.0->weaver-core) (3.1.3)\n",
            "Requirement already satisfied: ndindex in /usr/local/lib/python3.11/dist-packages (from blosc2>=2.3.0->tables>=3.6.1->weaver-core) (1.10.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from blosc2>=2.3.0->tables>=3.6.1->weaver-core) (1.1.1)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from blosc2>=2.3.0->tables>=3.6.1->weaver-core) (4.3.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from blosc2>=2.3.0->tables>=3.6.1->weaver-core) (2.32.3)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=4.13.0->awkward>=1.8.0->weaver-core) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.2.0->weaver-core) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->blosc2>=2.3.0->tables>=3.6.1->weaver-core) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->blosc2>=2.3.0->tables>=3.6.1->weaver-core) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->blosc2>=2.3.0->tables>=3.6.1->weaver-core) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->blosc2>=2.3.0->tables>=3.6.1->weaver-core) (2025.7.9)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.11/dist-packages (1.22.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install weaver-core\n",
        "! pip install onnxruntime\n",
        "#! pip install torch torchvision torchaudio # google colab has torch installed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYfV8pMmx0So"
      },
      "source": [
        "# Exploring JetClass-II\n",
        "\n",
        "Load a few entries from JetClass-II as an example and display their data structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpsUq3RWyF1g",
        "outputId": "8e2d0cad-68fc-4ebb-9811-14f9430ffb36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-07-14 22:23:29 URL:https://raw.githubusercontent.com/jet-universe/sophon/main/notebooks/JetClassII_example.parquet [447746/447746] -> \"JetClassII_example.parquet.4\" [1]\n"
          ]
        }
      ],
      "source": [
        "! wget --no-verbose https://github.com/jet-universe/sophon/raw/main/notebooks/JetClassII_example.parquet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "Ap2uAcSdx0Sp",
        "outputId": "5584e1c6-b693-4123-c96b-f42d3b3db034"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<pre>[{part_px: [-202, -140, ..., -0.491], part_py: [29, ...], part_pz: [...], ...},\n",
              " {part_px: [34, 21.7, ..., 0.491, 0.405], part_py: [...], part_pz: [...], ...},\n",
              " {part_px: [-99.6, -17.8, ..., -0.48], part_py: [-27.3, ...], ...},\n",
              " {part_px: [-17.1, -17.5, ..., -0.109], part_py: [-58.8, ...], ...},\n",
              " {part_px: [-19.8, -11.1, ..., 0.0862], part_py: [39.2, ...], ...},\n",
              " {part_px: [70.2, 22.7], part_py: [-930, -402], part_pz: [...], ...},\n",
              " {part_px: [-94.3, -19.9, ..., -0.501], part_py: [-84.1, ...], ...},\n",
              " {part_px: [78.5, 29.4, ..., 0.318, 0.285], part_py: [...], part_pz: ..., ...},\n",
              " {part_px: [-525, -330, ..., -1.53, -1.42], part_py: [...], part_pz: ..., ...},\n",
              " {part_px: [105, 82.9, ..., 0.656, 0.554], part_py: [67.5, ...], ...},\n",
              " ...,\n",
              " {part_px: [-48.4, -28.4, ..., -0.761], part_py: [-162, ...], ...},\n",
              " {part_px: [40.2, 40.7, ..., 0.123, 0.317], part_py: [...], part_pz: ..., ...},\n",
              " {part_px: [-27.4, -33.1, ..., -0.134], part_py: [51.8, ...], ...},\n",
              " {part_px: [-36, -21.6, ..., -0.438], part_py: [-67.8, ...], part_pz: ..., ...},\n",
              " {part_px: [23.6, 21.2, ..., 0.422, 0.702], part_py: [...], part_pz: ..., ...},\n",
              " {part_px: [-264, -25.3, ..., -0.126], part_py: [-830, ...], part_pz: ..., ...},\n",
              " {part_px: [513, 274, ..., 0.901, 0.853], part_py: [-173, ...], ...},\n",
              " {part_px: [187, 37.9, ..., 0.904, 0.401], part_py: [44.1, ...], ...},\n",
              " {part_px: [-40.7, -36.8, ..., -0.188], part_py: [-134, ...], ...}]\n",
              "--------------------------------------------------------------------------------\n",
              "backend: cpu\n",
              "nbytes: 572.3 kB\n",
              "type: 100 * {\n",
              "    part_px: var * float32,\n",
              "    part_py: var * float32,\n",
              "    part_pz: var * float32,\n",
              "    part_energy: var * float32,\n",
              "    part_deta: var * float32,\n",
              "    part_dphi: var * float32,\n",
              "    part_d0val: var * float32,\n",
              "    part_d0err: var * float32,\n",
              "    part_dzval: var * float32,\n",
              "    part_dzerr: var * float32,\n",
              "    ...\n",
              "}</pre>"
            ],
            "text/plain": [
              "<Array [{part_px: [...], ...}, ..., {...}] type='100 * {part_px: var * floa...'>"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ],
      "source": [
        "import awkward as ak\n",
        "\n",
        "arrays = ak.from_parquet(\"JetClassII_example.parquet\")\n",
        "arrays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSOYlIikx0Sq"
      },
      "source": [
        "The entries are jet-based. Each entry includes\n",
        "\n",
        " - the jet features (`jet_*`),\n",
        " - the jet constituent's features (`part_*`),\n",
        " - the GEN-jet features (`genjet_*`) if a matched GEN-jet is found, and\n",
        " - the GEN-jet constituent's features (`genpart_*`).\n",
        " - auxiliary features for selected truth particles (`aux_genpart_*`)\n",
        "\n",
        "Display the content of each branch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRuBiTfJx0Sr",
        "outputId": "623169ed-3e28-4ddf-cdf7-f24748f03f3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "part_px :  [[-202, -140, -76.9, -49.3, -44.9, ..., -0.866, -0.597, -0.563, -0.491], ...]\n",
            "part_py :  [[29, -104, -2.95, -1.38, -1.01, ..., -0.175, 0.213, 0.322, 0.19, -0.253], ...]\n",
            "part_pz :  [[-44, -65.4, -54.7, -34.4, -32.4, ..., -0.474, -0.289, 0.0158, -0.752], ...]\n",
            "part_energy :  [[209, 186, 94.5, 60.2, 55.4, 51.3, ..., 0.954, 1.01, 0.737, 0.594, 0.933], ...]\n",
            "part_deta :  [[-0.232, -0.0793, 0.215, 0.204, ..., 0.0635, -0.0315, -0.473, 0.669], ...]\n",
            "part_dphi :  [[-0.251, 0.529, -0.07, -0.0804, ..., -0.349, -0.604, -0.434, 0.368], ...]\n",
            "part_d0val :  [[0.00359, -0.0036, -0.0101, 0.0104, 0, -0.00337, ..., 0, 0, 0, 0, 0], ...]\n",
            "part_d0err :  [[0.011, 0.011, 0.011, 0.0116, 0, 0.0116, ..., 0.0926, 0, 0, 0, 0, 0], ...]\n",
            "part_dzval :  [[-0.0224, 0.0094, -0.00443, -0.0521, 0, -0.00956, ..., 0, 0, 0, 0, 0], ...]\n",
            "part_dzerr :  [[0.0318, 0.0318, 0.0316, 0.0316, 0, 0.0348, ..., 0.198, 0, 0, 0, 0, 0], ...]\n",
            "part_charge :  [[1, -1, 1, -1, 0, -1, 1, -1, 1, 1, 1, ..., 0, 0, 0, 0, -1, 0, 0, 0, 0, 0], ...]\n",
            "part_isElectron :  [[True, True, False, False, False, ..., False, False, False, False, False], ...]\n",
            "part_isMuon :  [[False, False, False, False, False, ..., False, False, False, False], ...]\n",
            "part_isPhoton :  [[False, False, False, False, True, ..., True, True, True, True, True], ...]\n",
            "part_isChargedHadron :  [[False, False, True, True, False, ..., False, False, False, False, False], ...]\n",
            "part_isNeutralHadron :  [[False, False, False, False, False, ..., False, False, False, False], ...]\n",
            "jet_pt :  [717, 258, 210, 290, 202, 1.34e+03, ..., 518, 499, 1.29e+03, 1.64e+03, 385, 450]\n",
            "jet_eta :  [-0.446, 1.27, -1.12, 0.516, -0.259, ..., -1.12, 1, -0.154, -0.0162, -1.69]\n",
            "jet_phi :  [-3.03, -0.761, -2.84, -1.93, 2.41, ..., 0.954, -1.85, -0.341, 0.453, -2.05]\n",
            "jet_energy :  [837, 504, 367, 331, 225, 1.63e+03, ..., 869, 2e+03, 1.67e+03, 408, 1.28e+03]\n",
            "jet_sdmass :  [275, 50.1, 89.6, 38.6, 83.5, 100, 116, ..., 190, 202, 97.8, 30.4, 136, 169]\n",
            "jet_nparticles :  [42, 53, 34, 25, 42, 2, 35, 24, 20, 55, ..., 38, 68, 58, 82, 56, 30, 31, 23, 52]\n",
            "jet_tau1 :  [0.416, 0.321, 0.366, 0.148, 0.463, ..., 0.429, 0.0521, 0.0386, 0.347, 0.307]\n",
            "jet_tau2 :  [0.245, 0.181, 0.21, 0.0745, 0.0869, ..., 0.279, 0.0121, 0.0232, 0.0989, 0.115]\n",
            "jet_tau3 :  [0.0513, 0.148, 0.111, 0.0399, 0.0613, ..., 0.00953, 0.0127, 0.0339, 0.0869]\n",
            "jet_tau4 :  [0.0377, 0.104, 0.0472, 0.0295, 0.0568, ..., 0.00774, 0.00831, 0.0252, 0.0616]\n",
            "jet_label :  [92, 28, 31, 102, 60, 11, 99, 62, 187, ..., 73, 130, 71, 33, 3, 187, 113, 49]\n",
            "genpart_px :  [[-201, -140, -73.9, -47.4, -40.4, ..., -0.151, -0.133, -0.0684, -0.00421], ...]\n",
            "genpart_py :  [[28.9, -104, -2.83, -1.32, ..., -0.00632, 0.00145, -0.00149, 0.00036], ...]\n",
            "genpart_pz :  [[-36.9, -59.6, -50, -31.4, ..., 0.0412, -0.0167, -0.078, -0.000644], ...]\n",
            "genpart_energy :  [[207, 185, 89.3, 56.9, 48.5, ..., 0.158, 0.156, 0.134, 0.104, 0.00428], ...]\n",
            "genpart_jet_deta :  [[-0.266, -0.111, 0.187, 0.176, 0.175, ..., -0.716, -0.321, 0.531, -0.295], ...]\n",
            "genpart_jet_dphi :  [[-0.251, 0.529, -0.07, -0.0804, ..., -0.0664, -0.119, -0.0865, -0.194], ...]\n",
            "genpart_x :  [[0, 0, 0, 0, 0, 0, ..., -0.000797, 0, -8.97e-05, -0.000326, -8.97e-05, 0], ...]\n",
            "genpart_y :  [[0, 0, 0, 0, 0, 0, ..., 0.000287, 0, -3.15e-06, 8.19e-05, -3.15e-06, 0], ...]\n",
            "genpart_z :  [[0, 0, 0, 0, 0, 0, ..., -0.00037, 0, -1.53e-05, -9.92e-05, -1.53e-05, 0], ...]\n",
            "genpart_t :  [[0, 0, 0, 0, 0, 0, ..., 3.08e-15, 0, 3.47e-16, 1.17e-15, 3.47e-16, 0], ...]\n",
            "genpart_pid :  [[-11, 11, 321, -321, -211, 321, 22, ..., -321, 22, 22, 22, 22, 22, 22], ...]\n",
            "genjet_pt :  [724, 303, 247, 458, 302, 1.34e+03, ..., 557, 553, 1.44e+03, 3.42e+03, 396, 523]\n",
            "genjet_eta :  [-0.447, 1.36, -1.16, 0.574, -0.185, ..., -1.06, 1, -0.158, -0.015, -1.67]\n",
            "genjet_phi :  [-3.03, -0.752, -2.87, -1.96, 2.53, ..., 0.966, -1.85, -0.338, 0.463, -2.09]\n",
            "genjet_energy :  [846, 641, 449, 543, 329, 1.64e+03, ..., 928, 2.22e+03, 3.47e+03, 418, 1.45e+03]\n",
            "genjet_sdmass :  [282, 110, 117, 59.5, 118, 100, 119, ..., 199, 208, 234, 98.4, 32.9, 133, 225]\n",
            "genjet_nparticles :  [63, 86, 60, 48, 71, 13, 64, 41, 42, ..., 64, 91, 68, 110, 83, 52, 77, 38, 73]\n",
            "aux_genpart_pt :  [[867, 529, 350, 302, 304, 175, 203], ..., [526, 216, 324, ..., 118, 285, 40.5]]\n",
            "aux_genpart_eta :  [[-0.491, -0.615, -0.272, -0.454, -0.628, -0.335, -0.181], ..., [-1.68, ...]]\n",
            "aux_genpart_phi :  [[-2.72, -2.59, -2.93, -2.08, -3.1, -2.5, 3], ..., [-2.09, -2.37, ..., -2.22]]\n",
            "aux_genpart_mass :  [[495, 303, 146, 0.5, 0.5, 0.000511, 0.000511], ..., [230, 94.4, ..., 0.33]]\n",
            "aux_genpart_pid :  [[25, 35, 35, 3, -3, 11, -11], [25, ..., -2], ..., [25, 37, -37, -3, 2, 3, -2]]\n",
            "aux_genpart_isResX :  [[True, False, False, False, False, False, False], ..., [True, ..., False]]\n",
            "aux_genpart_isResY :  [[False, True, True, False, False, False, False], ..., [False, ..., False]]\n",
            "aux_genpart_isResDecayProd :  [[False, False, False, True, True, True, True], ..., [False, False, ..., True]]\n",
            "aux_genpart_isTauDecayProd :  [[False, False, False, False, False, False, False], ..., [False, ..., False]]\n",
            "aux_genpart_isQcdParton :  [[False, False, False, False, False, False, False], ..., [False, ..., False]]\n"
          ]
        }
      ],
      "source": [
        "for branch in arrays.fields:\n",
        "    print(branch, ': ', arrays[branch])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iyz3miF9x0Ss"
      },
      "source": [
        "# Visualizing JetClass-II\n",
        "\n",
        "Let's visualize the jet and the matched GEN-jet as point clouds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "ucv6V3X0x0Ss"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "label_list = [\"label_X_bb\", \"label_X_cc\", \"label_X_ss\", \"label_X_qq\", \"label_X_bc\", \"label_X_cs\", \"label_X_bq\", \"label_X_cq\", \"label_X_sq\", \"label_X_gg\", \"label_X_ee\", \"label_X_mm\", \"label_X_tauhtaue\", \"label_X_tauhtaum\", \"label_X_tauhtauh\", \"label_X_YY_bbbb\", \"label_X_YY_bbcc\", \"label_X_YY_bbss\", \"label_X_YY_bbqq\", \"label_X_YY_bbgg\", \"label_X_YY_bbee\", \"label_X_YY_bbmm\", \"label_X_YY_bbtauhtaue\", \"label_X_YY_bbtauhtaum\", \"label_X_YY_bbtauhtauh\", \"label_X_YY_bbb\", \"label_X_YY_bbc\", \"label_X_YY_bbs\", \"label_X_YY_bbq\", \"label_X_YY_bbg\", \"label_X_YY_bbe\", \"label_X_YY_bbm\", \"label_X_YY_cccc\", \"label_X_YY_ccss\", \"label_X_YY_ccqq\", \"label_X_YY_ccgg\", \"label_X_YY_ccee\", \"label_X_YY_ccmm\", \"label_X_YY_cctauhtaue\", \"label_X_YY_cctauhtaum\", \"label_X_YY_cctauhtauh\", \"label_X_YY_ccb\", \"label_X_YY_ccc\", \"label_X_YY_ccs\", \"label_X_YY_ccq\", \"label_X_YY_ccg\", \"label_X_YY_cce\", \"label_X_YY_ccm\", \"label_X_YY_ssss\", \"label_X_YY_ssqq\", \"label_X_YY_ssgg\", \"label_X_YY_ssee\", \"label_X_YY_ssmm\", \"label_X_YY_sstauhtaue\", \"label_X_YY_sstauhtaum\", \"label_X_YY_sstauhtauh\", \"label_X_YY_ssb\", \"label_X_YY_ssc\", \"label_X_YY_sss\", \"label_X_YY_ssq\", \"label_X_YY_ssg\", \"label_X_YY_sse\", \"label_X_YY_ssm\", \"label_X_YY_qqqq\", \"label_X_YY_qqgg\", \"label_X_YY_qqee\", \"label_X_YY_qqmm\", \"label_X_YY_qqtauhtaue\", \"label_X_YY_qqtauhtaum\", \"label_X_YY_qqtauhtauh\", \"label_X_YY_qqb\", \"label_X_YY_qqc\", \"label_X_YY_qqs\", \"label_X_YY_qqq\", \"label_X_YY_qqg\", \"label_X_YY_qqe\", \"label_X_YY_qqm\", \"label_X_YY_gggg\", \"label_X_YY_ggee\", \"label_X_YY_ggmm\", \"label_X_YY_ggtauhtaue\", \"label_X_YY_ggtauhtaum\", \"label_X_YY_ggtauhtauh\", \"label_X_YY_ggb\", \"label_X_YY_ggc\", \"label_X_YY_ggs\", \"label_X_YY_ggq\", \"label_X_YY_ggg\", \"label_X_YY_gge\", \"label_X_YY_ggm\", \"label_X_YY_bee\", \"label_X_YY_cee\", \"label_X_YY_see\", \"label_X_YY_qee\", \"label_X_YY_gee\", \"label_X_YY_bmm\", \"label_X_YY_cmm\", \"label_X_YY_smm\", \"label_X_YY_qmm\", \"label_X_YY_gmm\", \"label_X_YY_btauhtaue\", \"label_X_YY_ctauhtaue\", \"label_X_YY_stauhtaue\", \"label_X_YY_qtauhtaue\", \"label_X_YY_gtauhtaue\", \"label_X_YY_btauhtaum\", \"label_X_YY_ctauhtaum\", \"label_X_YY_stauhtaum\", \"label_X_YY_qtauhtaum\", \"label_X_YY_gtauhtaum\", \"label_X_YY_btauhtauh\", \"label_X_YY_ctauhtauh\", \"label_X_YY_stauhtauh\", \"label_X_YY_qtauhtauh\", \"label_X_YY_gtauhtauh\", \"label_X_YY_qqqb\", \"label_X_YY_qqqc\", \"label_X_YY_qqqs\", \"label_X_YY_bbcq\", \"label_X_YY_ccbs\", \"label_X_YY_ccbq\", \"label_X_YY_ccsq\", \"label_X_YY_sscq\", \"label_X_YY_qqbc\", \"label_X_YY_qqbs\", \"label_X_YY_qqcs\", \"label_X_YY_bcsq\", \"label_X_YY_bcs\", \"label_X_YY_bcq\", \"label_X_YY_bsq\", \"label_X_YY_csq\", \"label_X_YY_bcev\", \"label_X_YY_csev\", \"label_X_YY_bqev\", \"label_X_YY_cqev\", \"label_X_YY_sqev\", \"label_X_YY_qqev\", \"label_X_YY_bcmv\", \"label_X_YY_csmv\", \"label_X_YY_bqmv\", \"label_X_YY_cqmv\", \"label_X_YY_sqmv\", \"label_X_YY_qqmv\", \"label_X_YY_bctauev\", \"label_X_YY_cstauev\", \"label_X_YY_bqtauev\", \"label_X_YY_cqtauev\", \"label_X_YY_sqtauev\", \"label_X_YY_qqtauev\", \"label_X_YY_bctaumv\", \"label_X_YY_cstaumv\", \"label_X_YY_bqtaumv\", \"label_X_YY_cqtaumv\", \"label_X_YY_sqtaumv\", \"label_X_YY_qqtaumv\", \"label_X_YY_bctauhv\", \"label_X_YY_cstauhv\", \"label_X_YY_bqtauhv\", \"label_X_YY_cqtauhv\", \"label_X_YY_sqtauhv\", \"label_X_YY_qqtauhv\", \"label_QCD_bbccss\", \"label_QCD_bbccs\", \"label_QCD_bbcc\", \"label_QCD_bbcss\", \"label_QCD_bbcs\", \"label_QCD_bbc\", \"label_QCD_bbss\", \"label_QCD_bbs\", \"label_QCD_bb\", \"label_QCD_bccss\", \"label_QCD_bccs\", \"label_QCD_bcc\", \"label_QCD_bcss\", \"label_QCD_bcs\", \"label_QCD_bc\", \"label_QCD_bss\", \"label_QCD_bs\", \"label_QCD_b\", \"label_QCD_ccss\", \"label_QCD_ccs\", \"label_QCD_cc\", \"label_QCD_css\", \"label_QCD_cs\", \"label_QCD_c\", \"label_QCD_ss\", \"label_QCD_s\", \"label_QCD_light\"]\n",
        "\n",
        "def color_fader(c1, c2, mix=0): # linear interpolate from color c1 (mix=0) to c2 (mix=1)\n",
        "    assert 0 <= mix <= 1\n",
        "    c1 = np.array(mpl.colors.to_rgb(c1))\n",
        "    c2 = np.array(mpl.colors.to_rgb(c2))\n",
        "    return mpl.colors.to_hex((1-mix)*c1 + mix*c2)\n",
        "\n",
        "def visualize_jet(ax, arr, is_genjet=True):\n",
        "    # part_type: 0: electron, 1: muon, 2: photon, 3: charged had, 4: neutral had\n",
        "    if not is_genjet:\n",
        "        jet_prefix, part_prefix = 'jet', 'part'\n",
        "        part_disp = np.hypot(arr['part_d0val'], arr['part_dzval']) # an estimation of displacement\n",
        "        part_type = ak.argmax([\n",
        "            arr['part_isElectron'],\n",
        "            arr['part_isMuon'],\n",
        "            arr['part_isPhoton'],\n",
        "            arr['part_isChargedHadron'],\n",
        "            arr['part_isNeutralHadron']\n",
        "        ], axis=0)\n",
        "    else:\n",
        "        jet_prefix, part_prefix = 'genjet', 'genpart'\n",
        "        part_disp = np.sqrt(arr['genpart_x']**2 + arr['genpart_y']**2 + arr['genpart_z']**2)\n",
        "        part_type = ak.argmax([\n",
        "            abs(arr['genpart_pid']) == 11,\n",
        "            abs(arr['genpart_pid']) == 13,\n",
        "            arr['genpart_pid'] == 22,\n",
        "            (abs(arr['genpart_pid']) == 211) | (abs(arr['genpart_pid']) == 321) | (abs(arr['genpart_pid']) == 2212),\n",
        "            (arr['genpart_pid'] == 130) | (arr['genpart_pid'] == 310) | (arr['genpart_pid'] == 2112)\n",
        "        ], axis=0)\n",
        "    radius_fn = lambda pt: np.sqrt(pt) / 200\n",
        "\n",
        "    # draw particles\n",
        "    for i in range(arr[f\"{jet_prefix}_nparticles\"]):\n",
        "        if not is_genjet:\n",
        "            px, py, deta, dphi = map(lambda x: arr[f\"part_{x}\"][i], ['px', 'py', 'deta', 'dphi'])\n",
        "        else:\n",
        "            px, py, deta, dphi = map(lambda x: arr[f\"genpart_{x}\"][i], ['px', 'py', 'jet_deta', 'jet_dphi'])\n",
        "        pt = np.hypot(px, py)\n",
        "\n",
        "        color = color_fader('#74c476', '#081d58', mix=np.tanh(part_disp[i]))\n",
        "        if part_type[i] == 0: # electrons\n",
        "            ax.add_patch(mpl.patches.RegularPolygon((deta, dphi), 3, radius=radius_fn(pt), clip_on=True, alpha=0.3, edgecolor='black', facecolor=color))\n",
        "        elif part_type[i] == 1: # muons\n",
        "            ax.add_patch(mpl.patches.RegularPolygon((deta, dphi), 3, radius=radius_fn(pt), orientation=np.pi, clip_on=True, alpha=0.3, edgecolor='black', facecolor=color))\n",
        "        elif part_type[i] == 2: # photons\n",
        "            ax.add_patch(mpl.patches.RegularPolygon((deta, dphi), 5, radius=radius_fn(pt), clip_on=True, alpha=0.3, edgecolor=color, facecolor='none'))\n",
        "        elif part_type[i] == 3: # charged hadrons\n",
        "            ax.add_patch(plt.Circle((deta, dphi), radius_fn(pt), clip_on=True, alpha=0.3, facecolor=color))\n",
        "        elif part_type[i] == 4: # neutral hadrons\n",
        "            ax.add_patch(plt.Circle((deta, dphi), radius_fn(pt), clip_on=True, alpha=0.3, edgecolor=color, facecolor='none'))\n",
        "\n",
        "        # if is_genjet:\n",
        "        #     ax.text(deta, dphi, str(arr.genpart_pid[i]), ha='center', va='center', fontsize=4) # annotate particle PDGIDs\n",
        "\n",
        "    # auxiliary truth particles if this is a genjet\n",
        "    if is_genjet:\n",
        "        for i in range(len(arr[\"aux_genpart_pt\"])):\n",
        "            color = 'yellow' if arr.aux_genpart_isResX[i] else 'gold' if arr.aux_genpart_isResY[i] else 'orange' if arr.aux_genpart_isResDecayProd[i] else None\n",
        "            if color is None:\n",
        "                continue\n",
        "            pt = arr.aux_genpart_pt[i]\n",
        "            deta = np.sign(arr.jet_eta) * (arr.aux_genpart_eta[i] - arr.jet_eta)\n",
        "            dphi = (arr.aux_genpart_phi[i] - arr.jet_phi + np.pi) % (2*np.pi) - np.pi\n",
        "            pid = arr.aux_genpart_pid[i]\n",
        "            if abs(deta) > 0.8 or abs(dphi) > 0.8:\n",
        "                continue\n",
        "\n",
        "            # draw squares for auxiliary particles\n",
        "            ax.add_patch(mpl.patches.RegularPolygon((deta, dphi), 4, radius=radius_fn(pt), clip_on=True, alpha=0.2, facecolor=color))\n",
        "            ax.text(deta, dphi, str(pid), ha='center', va='center', fontsize=5) # annotate particle PDGIDs\n",
        "\n",
        "    ax.set_xlabel(r'$\\Delta\\eta$'); ax.set_ylabel(r'$\\Delta\\phi$')\n",
        "    ax.set_xlim(-0.8, 0.8); ax.set_ylim(-0.8, 0.8)\n",
        "    ax.set_aspect('equal')\n",
        "\n",
        "    # annotate basic info\n",
        "    ax.text(0.02, 0.98, r'$\\mathbf{%s}$ $p_{\\rm T}$: %.0f GeV, $m_{\\rm SD}$: %.0f GeV' % (jet_prefix, arr[f\"{jet_prefix}_pt\"], arr[f\"{jet_prefix}_sdmass\"]), ha='left', va='top', transform=ax.transAxes)\n",
        "    if not is_genjet:\n",
        "        ax.text(0.02, 0.91, r'truth label: %s' % label_list[arr[f\"{jet_prefix}_label\"]][6:], ha='left', va='top', transform=ax.transAxes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5WEfHG3x0St"
      },
      "source": [
        "Left subplot: jet, right subplot: matched GEN-jet\n",
        "\n",
        "Note:\n",
        " - Hadrons = **circles**; electrons/muons = **triangles** (upward/downward); photons = **pentagons**.\n",
        " - Charged particles = **solid** markers; neutral particles = **hollow** markers.\n",
        " - Larger displacement -> more **blue**.\n",
        "\n",
        "For GEN-jet:\n",
        " - the GEN resonances (X, Y) = **(yellow, gold) squares**; decay products = **orange squares**, PDGIDs annotated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "uETr_Rf1x0St"
      },
      "outputs": [],
      "source": [
        "i = 1  # draw entry number i\n",
        "\n",
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "visualize_jet(ax1, arrays[i], is_genjet=False)\n",
        "visualize_jet(ax2, arrays[i], is_genjet=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6R-_5Fxx0Su"
      },
      "source": [
        "# Inferring Sophon model\n",
        "\n",
        "Download the Sophon ONNX model from Hugging Face."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hR1KRD8y39d",
        "outputId": "644ceeb2-ed7c-4391-8dcb-c95c2974b47b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-07-14 22:23:31 URL:https://cdn-lfs-us-1.hf.co/repos/4a/b9/4ab947e5de3182c3f0fe6225553fb30b989aabcea1ec7f653a4c814f62f36c41/f54e9fd56b12e22ef4266e40b683dbf8533139b55cdab1b1c127d6e7cb8e2fd4?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.onnx%3B+filename%3D%22model.onnx%22%3B&Expires=1752535411&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MjUzNTQxMX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzRhL2I5LzRhYjk0N2U1ZGUzMTgyYzNmMGZlNjIyNTU1M2ZiMzBiOTg5YWFiY2VhMWVjN2Y2NTNhNGM4MTRmNjJmMzZjNDEvZjU0ZTlmZDU2YjEyZTIyZWY0MjY2ZTQwYjY4M2RiZjg1MzMxMzliNTVjZGFiMWIxYzEyN2Q2ZTdjYjhlMmZkND9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=HcUbbXe2X5mpEL1nchiGTz7bRFk1CI5lUersVHywceHTl3H3bq0DwrXen4DdT1cRpy7x-NRn8yK2aRKFoxA9NRv8y%7EckIcoEAbZXFx1JbLOcP8xz7qD3pAGJPvNFs9JeErlUTfSb%7EJNbEo0A48pA4IZ5bBEfTW4fStD0ZHqEd5HaZTJr53UPA6AR0DZ4TdaaSFoHcahJQncPbMKKAxN82xm0p6A-89SDHPpii9uFuuHaEdclbAiDdPv6ESIIYXrnHIgw7PIO1-Wz3ZaThFdYoztQrI9hO3-BbXi7VIwfEycfTqU-E56adudFTl%7E5rRTte0K5-ki1W%7EYyvAPa2-syVw__&Key-Pair-Id=K24J24Z295AEI9 [9328171/9328171] -> \"JetClassII_Sophon.onnx\" [1]\n"
          ]
        }
      ],
      "source": [
        "! wget --no-verbose https://huggingface.co/jet-universe/sophon/resolve/main/models/JetClassII_Sophon/model.onnx -O JetClassII_Sophon.onnx"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start an ONNX Runtime session."
      ],
      "metadata": {
        "id": "iAV3SxP7xW-F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "8w8jidTPx0Su"
      },
      "outputs": [],
      "source": [
        "import onnxruntime as ort\n",
        "\n",
        "ort_sess = ort.InferenceSession('JetClassII_Sophon.onnx')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAzcSc2Ix0Su"
      },
      "source": [
        "Make input variables and do inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "vx2ysaN5x0Su"
      },
      "outputs": [],
      "source": [
        "def make_input_feats(arr):\n",
        "    # calculate all input features to the Sophon model\n",
        "    input_feats = {}\n",
        "\n",
        "    # existing variables\n",
        "    for var in ['part_deta', 'part_dphi', 'part_charge', 'part_d0err', 'part_dzerr', 'part_isElectron', 'part_isMuon', 'part_isPhoton', 'part_isChargedHadron', 'part_isNeutralHadron']:\n",
        "        input_feats[var] = ak.values_astype(arr[var], np.float32)\n",
        "    # new variables\n",
        "    input_feats['part_mask'] = ak.ones_like(arr.part_px)\n",
        "    input_feats['part_px_scale'] = arr.part_px / arr.jet_pt * 500\n",
        "    input_feats['part_py_scale'] = arr.part_py / arr.jet_pt * 500\n",
        "    input_feats['part_pz_scale'] = arr.part_pz / arr.jet_pt * 500\n",
        "    input_feats['part_energy_scale'] = arr.part_energy / arr.jet_pt * 500\n",
        "    input_feats['part_pt'] = np.hypot(arr.part_px, arr.part_py)\n",
        "    input_feats['part_pt_scale'] = np.hypot(input_feats['part_px_scale'], input_feats['part_py_scale'])\n",
        "    input_feats['part_pt_scale_log'] = np.log(input_feats['part_pt_scale'])\n",
        "    input_feats['part_e_scale_log'] = np.log(input_feats['part_energy_scale'])\n",
        "    input_feats['part_logptrel'] = np.log(input_feats['part_pt'] / arr.jet_pt)\n",
        "    input_feats['part_logerel'] = np.log(arr.part_energy / arr.jet_energy)\n",
        "    input_feats['part_deltaR'] = np.hypot(arr.part_deta, arr.part_dphi)\n",
        "    input_feats['part_d0'] = np.tanh(arr.part_d0val)\n",
        "    input_feats['part_dz'] = np.tanh(arr.part_dzval)\n",
        "\n",
        "    return input_feats\n",
        "\n",
        "\n",
        "def infer_model(input_feats, debug=False):\n",
        "    # define data structure and config\n",
        "    input_names = [\"pf_features\", \"pf_vectors\", \"pf_mask\"]\n",
        "    input_shapes = [(1, 17, 128), (1, 4, 128), (1, 1, 128)] # (batch_size=1, channel, length)\n",
        "    input_var_info = [ # (name, subtract_val, multiply_val, clip_min, clip_max)\n",
        "        [\n",
        "            (\"part_pt_scale_log\", 1.7, 0.7, -5, 5),\n",
        "            (\"part_e_scale_log\", 2.0, 0.7, -5, 5),\n",
        "            (\"part_logptrel\", -4.7, 0.7, -5, 5),\n",
        "            (\"part_logerel\", -4.7, 0.7, -5, 5),\n",
        "            (\"part_deltaR\", 0.2, 4.0, -5, 5),\n",
        "            (\"part_charge\", 0, 1, -1e8, 1e8),\n",
        "            (\"part_isChargedHadron\", 0, 1, -1e8, 1e8),\n",
        "            (\"part_isNeutralHadron\", 0, 1, -1e8, 1e8),\n",
        "            (\"part_isPhoton\", 0, 1, -1e8, 1e8),\n",
        "            (\"part_isElectron\", 0, 1, -1e8, 1e8),\n",
        "            (\"part_isMuon\", 0, 1, -1e8, 1e8),\n",
        "            (\"part_d0\", 0, 1, -1e8, 1e8),\n",
        "            (\"part_d0err\", 0, 1, 0, 1),\n",
        "            (\"part_dz\", 0, 1, -1e8, 1e8),\n",
        "            (\"part_dzerr\", 0, 1, 0, 1),\n",
        "            (\"part_deta\", 0, 1, -1e8, 1e8),\n",
        "            (\"part_dphi\", 0, 1, -1e8, 1e8),\n",
        "        ],\n",
        "        [\n",
        "            (\"part_px_scale\", 0, 1, -1e8, 1e8),\n",
        "            (\"part_py_scale\", 0, 1, -1e8, 1e8),\n",
        "            (\"part_pz_scale\", 0, 1, -1e8, 1e8),\n",
        "            (\"part_energy_scale\", 0, 1, -1e8, 1e8),\n",
        "        ],\n",
        "        [\n",
        "            (\"part_mask\", 0, 1, -1e8, 1e8),\n",
        "        ],\n",
        "    ]\n",
        "\n",
        "    input = {name: [] for name in input_names}\n",
        "    for name, shape, var_info in zip(input_names, input_shapes, input_var_info):\n",
        "        if (debug):\n",
        "            print(\"====== Preprocessed input: \", name, shape, \"======\")\n",
        "        length = shape[-1]\n",
        "        for var, sub, mul, clip_min, clip_max in var_info:\n",
        "            v = ak.to_numpy(input_feats[var])\n",
        "            v = (v - sub) * mul  # variable shifting and scaling\n",
        "            v = np.pad(v, (0, length))[:length] # zero-padding to fixed length\n",
        "            v = np.clip(v, clip_min, clip_max)  # clipping\n",
        "            input[name].append(v)\n",
        "            if (debug):\n",
        "                print(' - ', var, v)\n",
        "\n",
        "        input[name] = np.stack(input[name]).reshape(shape)\n",
        "\n",
        "    # run inference\n",
        "    ort_out = ort_sess.run(None, input)\n",
        "    return ort_out[0][0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSJ76Rfqx0Sv",
        "outputId": "4eca784f-d2b8-4738-acb2-695ccc37b1ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sophon model scores (len=188): [0.00087492 0.00014806 0.00021878 0.00013643 0.00019383] ...\n",
            "Sophon model latent features (len=128): [-0.00624361  0.00927145 -0.02239747 -0.00590648 -0.01222859] ...\n"
          ]
        }
      ],
      "source": [
        "i = 1  # infer jet entry number i\n",
        "\n",
        "input_feats = make_input_feats(arrays[i])\n",
        "output = infer_model(input_feats, debug=False)\n",
        "probs, hidneurons = output[:188], output[188:]\n",
        "\n",
        "print('Sophon model scores (len=188):', probs[:5], '...')\n",
        "print('Sophon model latent features (len=128):', hidneurons[:5], '...')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr-b3NgQx0Sv"
      },
      "source": [
        "# Visualizing Sophon's output probabilities\n",
        "\n",
        "Given a jet entry, find the top-5 probabilities interpreted by the Sophon model, and visualize these probabilities alongside the jet's visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "6de3tQQJx0Sv"
      },
      "outputs": [],
      "source": [
        "def visualize_top5_probs(ax, probs):\n",
        "    from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
        "    axin = inset_axes(ax, width=\"20%\", height=\"20%\", loc='lower right')\n",
        "\n",
        "    top_inds = np.argsort(probs)[::-1][:5]\n",
        "    axin.barh([label_list[i][6:] for i in top_inds], probs[top_inds], color='skyblue')\n",
        "    axin.invert_yaxis()\n",
        "    axin.xaxis.tick_top()\n",
        "    axin.tick_params(axis='both', which='major', labelsize=6)\n",
        "    axin.set_title('Sophon\\'s\\nTop-5 probs', fontsize=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "8-TSYKCDx0Sv"
      },
      "outputs": [],
      "source": [
        "i = 0  # draw entry number i\n",
        "\n",
        "# infer scores\n",
        "input_feats = make_input_feats(arrays[i])\n",
        "probs = infer_model(input_feats, debug=False)[:188]\n",
        "\n",
        "# make plots\n",
        "f, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
        "visualize_jet(ax, arrays[i], is_genjet=False)\n",
        "visualize_top5_probs(ax, probs)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2xuNat-3Se1",
        "outputId": "fb093f88-8d12-45df-d4c7-9ce0ecd3799e"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "example_ParticleTransformer_sophon.py  JetClassII_example.parquet.4\n",
            "JetClassII_example.parquet\t       JetClassII_Sophon.onnx\n",
            "JetClassII_example.parquet.1\t       __pycache__\n",
            "JetClassII_example.parquet.2\t       sample_data\n",
            "JetClassII_example.parquet.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/hqucms/weaver-core.git"
      ],
      "metadata": {
        "id": "ztO8czDnD2IB",
        "outputId": "c4014ffb-f2c1-447f-d953-9441c1ac6bdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'weaver-core'...\n",
            "remote: Enumerating objects: 977, done.\u001b[K\n",
            "remote: Counting objects: 100% (438/438), done.\u001b[K\n",
            "remote: Compressing objects: 100% (107/107), done.\u001b[K\n",
            "remote: Total 977 (delta 403), reused 331 (delta 331), pack-reused 539 (from 2)\u001b[K\n",
            "Receiving objects: 100% (977/977), 246.74 KiB | 6.33 MiB/s, done.\n",
            "Resolving deltas: 100% (660/660), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "uoCG3XfQ7A1w",
        "outputId": "0fbba409-f1ee-445c-f737-ad8da031fddc"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-67930add-8bb5-43e9-8da9-74eb7ed1d294\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-67930add-8bb5-43e9-8da9-74eb7ed1d294\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving example_ParticleTransformer_sophon.py to example_ParticleTransformer_sophon (2).py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from example_ParticleTransformer_sophon import get_model\n"
      ],
      "metadata": {
        "id": "2lxkh58w7avG"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# kinematic features (vectors)\n",
        "px = arrays['part_px']\n",
        "py = arrays['part_py']\n",
        "pz = arrays['part_pz']\n",
        "penergy = arrays['part_energy']\n",
        "# turn into a nested awkward array(dictionary)\n",
        "knmtc_points = ak.zip({\n",
        "    \"px\": px,\n",
        "    \"py\": py,\n",
        "    \"pz\": pz,\n",
        "    \"E\": penergy\n",
        "}, depth_limit=1)\n",
        "\n",
        "# padding in order to mask=mask\n",
        "# according to doc ak.pad_none() \"increases lengths of lists to a target length by adding None values.\"\n",
        "knmtc_padded = ak.pad_none(knmtc_points, target=100, axis=1, clip=True)"
      ],
      "metadata": {
        "id": "6lPDDBqb-HDW"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knmtc_list = ak.to_list(knmtc_padded)\n",
        "\n",
        "knmtc_cleaned = []\n",
        "for jet in knmtc_list:\n",
        "    if jet is None:\n",
        "        continue  # skip completely empty jets\n",
        "    clean_jet = []\n",
        "    for p in jet:\n",
        "        if p is None or not all(k in p for k in ['px', 'py', 'pz', 'E']):\n",
        "            clean_jet.append([0, 0, 0, 0])\n",
        "        else:\n",
        "            clean_jet.append([p['px'], p['py'], p['pz'], p['E']])\n",
        "    # pad to 100\n",
        "    while len(clean_jet) < 100:\n",
        "        clean_jet.append([0, 0, 0, 0])\n",
        "    knmtc_cleaned.append(clean_jet[:100])  # truncate if necessary\n",
        "\n",
        "# Convert to tensor\n",
        "knmtc_tensor = torch.tensor(knmtc_cleaned, dtype=torch.float)\n",
        "print(\"knmtc_tensor shape:\", knmtc_tensor.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oG3gN7Tf-IAh",
        "outputId": "7964743a-8a5d-4f6d-a925-793581c1fe6b"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "knmtc_tensor shape: torch.Size([100, 100, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Turn mask into boolean\n",
        "mask_bool = mask_tensor.bool()\n",
        "\n",
        "# 2. Extract points from Lorentz vectors (px, py, pz)\n",
        "points = knmtc_tensor[:, :, :3]  # shape: [B, 100, 3]\n",
        "\n",
        "# 3. Move everything to device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "points = points.to(device)\n",
        "features_tensor = features_tensor.to(device)\n",
        "knmtc_tensor = knmtc_tensor.to(device)\n",
        "mask_bool = mask_bool.to(device)\n"
      ],
      "metadata": {
        "id": "OAAhw2XP8H9R"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "part_features = ak.zip({\n",
        "    \"charge\": arrays['part_charge'],\n",
        "    \"electron\": arrays['part_isElectron'],\n",
        "    \"muon\": arrays['part_isMuon'],\n",
        "    \"photon\": arrays['part_isPhoton'],\n",
        "    \"chargedhadron\": arrays['part_isChargedHadron'],\n",
        "    \"neutralhadron\": arrays['part_isNeutralHadron']\n",
        "}, depth_limit=1)\n",
        "\n",
        "pfeats_padded = ak.pad_none(part_features, target=100, axis=1, clip=True)\n",
        "\n",
        "pfeats_list = ak.to_list(pfeats_padded)\n",
        "pfeats_cleaned = []\n",
        "\n",
        "for jet in pfeats_list:\n",
        "    if jet is None:\n",
        "        continue\n",
        "\n",
        "    n_particles = len(jet['charge'])  # number of particles (100)\n",
        "    clean_jet = []\n",
        "\n",
        "    for i in range(n_particles):\n",
        "        # addressing None value errors that kept coming up...\n",
        "        if any(jet[key][i] is None for key in jet):\n",
        "            clean_jet.append([0]*6)\n",
        "        else:\n",
        "            clean_jet.append([\n",
        "                jet['charge'][i],\n",
        "                jet['electron'][i],\n",
        "                jet['muon'][i],\n",
        "                jet['photon'][i],\n",
        "                jet['chargedhadron'][i],\n",
        "                jet['neutralhadron'][i]\n",
        "            ])\n",
        "\n",
        "    pfeats_cleaned.append(clean_jet)\n",
        "\n",
        "# to tensor\n",
        "features_tensor = torch.tensor(pfeats_cleaned, dtype=torch.float)\n",
        "print(\"features_tensor shape:\", features_tensor.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkd1VdrP-LNA",
        "outputId": "e0f8cd73-5763-433a-b120-6b3f80c4da14"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features_tensor shape: torch.Size([100, 100, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# addressing mask\n",
        "mask = ak.ones_like(arrays['part_px'], dtype=np.int32)\n",
        "mask_padded = ak.pad_none(mask, target=100, axis=1, clip=True)\n",
        "\n",
        "# mask/padding\n",
        "mask_filled = ak.fill_none(mask_padded, 0)\n",
        "\n",
        "# to tensor\n",
        "mask_tensor = torch.tensor(ak.to_numpy(mask_filled), dtype=torch.int)\n",
        "print(\"mask_tensor shape:\", mask_tensor.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ejbNEZs-NVh",
        "outputId": "10423485-ac43-49c9-80fe-923fb13ad18f"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mask_tensor shape: torch.Size([100, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from example_ParticleTransformer_sophon import get_model\n",
        "from example_ParticleTransformer_sophon import get_model\n",
        "from weaver.nn.model.ParticleTransformer import ParticleTransformer\n",
        "import torch\n",
        "from example_ParticleTransformer_sophon import ParticleTransformerSophonWrapper\n",
        "from example_ParticleTransformer_sophon import ParticleTransformerSophonWrapper\n",
        "\n",
        "from example_ParticleTransformer_sophon import ParticleTransformerSophonWrapper\n",
        "\n",
        "#  FIX: Lets define a corrected DummyDataConfig and call get_model with proper arguments\n",
        "\n",
        "class DummyDataConfig:\n",
        "    input_dicts = {\n",
        "        'pf_features': ['charge', 'electron', 'muon', 'photon', 'chargedhadron', 'neutralhadron']\n",
        "    }\n",
        "    input_names = ['points', 'features', 'lorentz_vectors', 'mask']\n",
        "    input_shapes = {\n",
        "        'points': (1, 100, 3),\n",
        "        'features': (1, 100, 6),\n",
        "        'lorentz_vectors': (1, 100, 4),\n",
        "        'mask': (1, 100)\n",
        "    }\n",
        "\n",
        "data_config = DummyDataConfig()\n",
        "\n",
        "#  Specify the number of classes (fixing the issue)\n",
        "model, _ = get_model(data_config, input_dim=6, num_classes=60)\n",
        "model.to(device)\n",
        "model.eval()  # still sets model to inference mode\n",
        "\n",
        "# No need to load checkpoint  model has random weights\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph6viau38Of6",
        "outputId": "c2d90c81-d81b-4a19-96bb-1a44f500aa7f"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ParticleTransformerSophonWrapper(\n",
              "  (mod): ParticleTransformer(\n",
              "    (trimmer): SequenceTrimmer()\n",
              "    (embed): Embed(\n",
              "      (input_bn): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (embed): Sequential(\n",
              "        (0): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
              "        (1): Linear(in_features=6, out_features=128, bias=True)\n",
              "        (2): GELU(approximate='none')\n",
              "        (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (4): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (5): GELU(approximate='none')\n",
              "        (6): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (7): Linear(in_features=512, out_features=128, bias=True)\n",
              "        (8): GELU(approximate='none')\n",
              "      )\n",
              "    )\n",
              "    (pair_embed): PairEmbed(\n",
              "      (embed): Sequential(\n",
              "        (0): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (1): Conv1d(4, 64, kernel_size=(1,), stride=(1,))\n",
              "        (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (3): GELU(approximate='none')\n",
              "        (4): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
              "        (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (6): GELU(approximate='none')\n",
              "        (7): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
              "        (8): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (9): GELU(approximate='none')\n",
              "        (10): Conv1d(64, 8, kernel_size=(1,), stride=(1,))\n",
              "        (11): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (blocks): ModuleList(\n",
              "      (0-7): 8 x Block(\n",
              "        (pre_attn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (post_attn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (pre_fc_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (act_dropout): Dropout(p=0.1, inplace=False)\n",
              "        (post_fc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (cls_blocks): ModuleList(\n",
              "      (0-1): 2 x Block(\n",
              "        (pre_attn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (post_attn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0, inplace=False)\n",
              "        (pre_fc_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (act_dropout): Dropout(p=0, inplace=False)\n",
              "        (post_fc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    (fc): Sequential(\n",
              "      (0): Linear(in_features=128, out_features=60, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Use batch size of 2, number of points N = 10, feature dims from your data_config (example)\n",
        "batch_size = 2\n",
        "N = 10  # number of particles (can vary, just pick something small for test)\n",
        "input_dim = len(data_config.input_dicts['pf_features'])  # from your data config, e.g. 6\n",
        "pair_dim = 4  # from your config\n",
        "\n",
        "# Dummy inputs - random floats, shapes must match model expectations\n",
        "points = torch.randn(batch_size, N, 3).to(device)           # e.g. 3D points (x,y,z) - adjust if needed\n",
        "features = torch.randn(batch_size, N, input_dim).to(device) # particle features\n",
        "lorentz_vectors = torch.randn(batch_size, N, 4).to(device)  # Lorentz vector for each particle\n",
        "mask = torch.zeros(batch_size, N, dtype=torch.bool).to(device)  # mask: False means valid, True means padded\n",
        "\n",
        "# Run forward pass\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  output = model(points, features, lorentz_vectors, mask)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "OIfs5-5j8UPB",
        "outputId": "b51586f2-6038-4a4c-aae8-6fca955c4aa5"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'ParticleTransformer' object has no attribute '_forward_encoder'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-189-3716300448.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlorentz_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/example_ParticleTransformer_sophon.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, points, features, lorentz_vectors, mask)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# return self.mod(features, v=lorentz_vectors, mask=mask) # not using the default foward implementation. Should add emport_embed flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlorentz_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_amp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1929\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ParticleTransformer' object has no attribute '_forward_encoder'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OAJen-j5A2BO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "weaver-uproot5",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}